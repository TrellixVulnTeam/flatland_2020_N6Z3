{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "def get_train_test(df,test_size=0.5):   \n",
    "    \"\"\"Split Data into train and test sets.\"\"\"\n",
    "    y = df.action\n",
    "    X = df.drop([\"action\"], axis=1)\n",
    "    X = pd.get_dummies(X,)\n",
    "    # X.drop(X.columns[X.std() == 0], axis=1, inplace=True)\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('final_test5.csv')\n",
    "df_original['action'] = df_original['action'].astype(int)\n",
    "df_original['priority'] = df_original['priority'].map(lambda x:x/df_original['priority'].max())\n",
    "df_original = df_original.drop(['handle'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('final_test1.csv')\n",
    "df_original['action'] = df_original['action'].astype(int)\n",
    "df_original['priority'] = df_original['priority'].map(lambda x:x/df_original['priority'].max())  # priority 归一化\n",
    "df_original = df_original.drop(['handle'],axis=1)    # 将handle这个特征删掉\n",
    "for i in range(2,300):\n",
    "    try:\n",
    "        filename = 'final_test' + str(i) + '.csv'\n",
    "        df_tmp = pd.read_csv(filename)\n",
    "        df_tmp['action'] = df_tmp['action'].astype(int)\n",
    "        df_tmp['priority'] = df_tmp['priority'].map(lambda x:x/df_tmp['priority'].max())\n",
    "        df_tmp = df_tmp.drop(['handle'],axis=1)\n",
    "        df_original = df_original.append(df_tmp, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    334056\n",
      "2    184100\n",
      "4     90618\n",
      "1     21782\n",
      "3     21679\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_original = df_original.dropna(axis=1,how='any')\n",
    "df_original.action.value_counts(normalize=True).plot(\n",
    "    kind=\"bar\", title=\"action\")\n",
    "plt.show()\n",
    "print(df_original.action.value_counts(normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_0 = df_original[df_original['action']==0].sample(n=21679,random_state=124,axis=0)\n",
    "tmp_2 = df_original[df_original['action']==2].sample(n=21679,random_state=124,axis=0)\n",
    "tmp_4 = df_original[df_original['action']==4].sample(n=21679,random_state=124,axis=0)\n",
    "tmp_1 = df_original[df_original['action']==1].sample(n=21679,random_state=124,axis=0)\n",
    "tmp_3 = df_original[df_original['action']==3]\n",
    "df = tmp_0.append([tmp_2,tmp_4,tmp_1,tmp_3], ignore_index=True)\n",
    "df = df.sample(frac=1)  # shuffle\n",
    "# xtrain, xtest, ytrain, ytest = get_train_test(df,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lomo/anaconda33/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2710/2710 - 10s - loss: 1.2024 - accuracy: 0.4890 - val_loss: 0.8544 - val_accuracy: 0.6263\n",
      "Epoch 2/300\n",
      "2710/2710 - 10s - loss: 0.8283 - accuracy: 0.6335 - val_loss: 0.7207 - val_accuracy: 0.6719\n",
      "Epoch 3/300\n",
      "2710/2710 - 10s - loss: 0.7546 - accuracy: 0.6635 - val_loss: 0.7047 - val_accuracy: 0.6802\n",
      "Epoch 4/300\n",
      "2710/2710 - 10s - loss: 0.7227 - accuracy: 0.6762 - val_loss: 0.6688 - val_accuracy: 0.7111\n",
      "Epoch 5/300\n",
      "2710/2710 - 10s - loss: 0.7015 - accuracy: 0.6863 - val_loss: 0.6382 - val_accuracy: 0.7153\n",
      "Epoch 6/300\n",
      "2710/2710 - 10s - loss: 0.6817 - accuracy: 0.6943 - val_loss: 0.6351 - val_accuracy: 0.7147\n",
      "Epoch 7/300\n",
      "2710/2710 - 10s - loss: 0.6726 - accuracy: 0.6977 - val_loss: 0.6322 - val_accuracy: 0.7163\n",
      "Epoch 8/300\n",
      "2710/2710 - 10s - loss: 0.6625 - accuracy: 0.7027 - val_loss: 0.6257 - val_accuracy: 0.7162\n",
      "Epoch 9/300\n",
      "2710/2710 - 10s - loss: 0.6627 - accuracy: 0.7009 - val_loss: 0.6281 - val_accuracy: 0.7064\n",
      "Epoch 10/300\n",
      "2710/2710 - 10s - loss: 0.6590 - accuracy: 0.7015 - val_loss: 0.6548 - val_accuracy: 0.6953\n",
      "Epoch 11/300\n",
      "2710/2710 - 10s - loss: 0.6517 - accuracy: 0.7026 - val_loss: 0.6213 - val_accuracy: 0.7133\n",
      "Epoch 12/300\n",
      "2710/2710 - 10s - loss: 0.6561 - accuracy: 0.7017 - val_loss: 0.5987 - val_accuracy: 0.7217\n",
      "Epoch 13/300\n",
      "2710/2710 - 10s - loss: 0.6472 - accuracy: 0.7062 - val_loss: 0.6285 - val_accuracy: 0.7177\n",
      "Epoch 14/300\n",
      "2710/2710 - 10s - loss: 0.6417 - accuracy: 0.7084 - val_loss: 0.6352 - val_accuracy: 0.6977\n",
      "Epoch 15/300\n",
      "2710/2710 - 10s - loss: 0.6421 - accuracy: 0.7089 - val_loss: 0.6002 - val_accuracy: 0.7207\n",
      "Epoch 16/300\n",
      "2710/2710 - 10s - loss: 0.6374 - accuracy: 0.7081 - val_loss: 0.6065 - val_accuracy: 0.7165\n",
      "Epoch 17/300\n",
      "2710/2710 - 10s - loss: 0.6340 - accuracy: 0.7118 - val_loss: 0.5952 - val_accuracy: 0.7259\n",
      "Epoch 18/300\n",
      "2710/2710 - 10s - loss: 0.6359 - accuracy: 0.7096 - val_loss: 0.6368 - val_accuracy: 0.7202\n",
      "Epoch 19/300\n",
      "2710/2710 - 10s - loss: 0.6353 - accuracy: 0.7114 - val_loss: 0.6143 - val_accuracy: 0.7151\n",
      "Epoch 20/300\n",
      "2710/2710 - 10s - loss: 0.6334 - accuracy: 0.7111 - val_loss: 0.6128 - val_accuracy: 0.7198\n",
      "Epoch 21/300\n",
      "2710/2710 - 10s - loss: 0.6339 - accuracy: 0.7110 - val_loss: 0.6053 - val_accuracy: 0.7161\n",
      "Epoch 22/300\n",
      "2710/2710 - 10s - loss: 0.6283 - accuracy: 0.7130 - val_loss: 0.6058 - val_accuracy: 0.7243\n",
      "Epoch 23/300\n",
      "2710/2710 - 10s - loss: 0.6353 - accuracy: 0.7107 - val_loss: 0.6037 - val_accuracy: 0.7236\n",
      "Epoch 24/300\n",
      "2710/2710 - 10s - loss: 0.6274 - accuracy: 0.7130 - val_loss: 0.6099 - val_accuracy: 0.7193\n",
      "Epoch 25/300\n",
      "2710/2710 - 10s - loss: 0.6290 - accuracy: 0.7134 - val_loss: 0.6145 - val_accuracy: 0.7187\n",
      "Epoch 26/300\n",
      "2710/2710 - 10s - loss: 0.6304 - accuracy: 0.7107 - val_loss: 0.6102 - val_accuracy: 0.7240\n",
      "Epoch 27/300\n",
      "2710/2710 - 10s - loss: 0.6287 - accuracy: 0.7114 - val_loss: 0.6021 - val_accuracy: 0.7210\n",
      "Epoch 28/300\n",
      "2710/2710 - 10s - loss: 0.6230 - accuracy: 0.7139 - val_loss: 0.6064 - val_accuracy: 0.7257\n",
      "Epoch 29/300\n",
      "2710/2710 - 10s - loss: 0.6170 - accuracy: 0.7154 - val_loss: 0.5986 - val_accuracy: 0.7258\n",
      "Epoch 30/300\n",
      "2710/2710 - 10s - loss: 0.6273 - accuracy: 0.7153 - val_loss: 0.5991 - val_accuracy: 0.7152\n",
      "Epoch 31/300\n",
      "2710/2710 - 10s - loss: 0.6208 - accuracy: 0.7157 - val_loss: 0.6363 - val_accuracy: 0.7224\n",
      "Epoch 32/300\n",
      "2710/2710 - 10s - loss: 0.6220 - accuracy: 0.7170 - val_loss: 0.6047 - val_accuracy: 0.7235\n",
      "Epoch 33/300\n",
      "2710/2710 - 10s - loss: 0.6181 - accuracy: 0.7164 - val_loss: 0.6185 - val_accuracy: 0.7201\n",
      "Epoch 34/300\n",
      "2710/2710 - 10s - loss: 0.6200 - accuracy: 0.7164 - val_loss: 0.5973 - val_accuracy: 0.7280\n",
      "Epoch 35/300\n",
      "2710/2710 - 10s - loss: 0.6167 - accuracy: 0.7163 - val_loss: 0.6665 - val_accuracy: 0.6860\n",
      "Epoch 36/300\n",
      "2710/2710 - 10s - loss: 0.6203 - accuracy: 0.7150 - val_loss: 0.6142 - val_accuracy: 0.7224\n",
      "Epoch 37/300\n",
      "2710/2710 - 10s - loss: 0.6144 - accuracy: 0.7182 - val_loss: 0.6175 - val_accuracy: 0.7173\n",
      "Epoch 38/300\n",
      "2710/2710 - 10s - loss: 0.6231 - accuracy: 0.7178 - val_loss: 0.6016 - val_accuracy: 0.7255\n",
      "Epoch 39/300\n",
      "2710/2710 - 10s - loss: 0.6205 - accuracy: 0.7161 - val_loss: 0.6500 - val_accuracy: 0.7189\n",
      "Epoch 40/300\n",
      "2710/2710 - 10s - loss: 0.6266 - accuracy: 0.7121 - val_loss: 0.6479 - val_accuracy: 0.7117\n",
      "Epoch 41/300\n",
      "2710/2710 - 10s - loss: 0.6187 - accuracy: 0.7158 - val_loss: 0.6167 - val_accuracy: 0.7245\n",
      "Epoch 42/300\n",
      "2710/2710 - 10s - loss: 0.6181 - accuracy: 0.7167 - val_loss: 0.6151 - val_accuracy: 0.7243\n",
      "Epoch 43/300\n",
      "2710/2710 - 10s - loss: 0.6185 - accuracy: 0.7157 - val_loss: 0.6031 - val_accuracy: 0.7232\n",
      "Epoch 44/300\n",
      "2710/2710 - 10s - loss: 0.6244 - accuracy: 0.7136 - val_loss: 0.6318 - val_accuracy: 0.7242\n",
      "Epoch 45/300\n",
      "2710/2710 - 10s - loss: 0.6184 - accuracy: 0.7154 - val_loss: 0.6119 - val_accuracy: 0.7232\n",
      "Epoch 46/300\n",
      "2710/2710 - 10s - loss: 0.6208 - accuracy: 0.7163 - val_loss: 0.6509 - val_accuracy: 0.7094\n",
      "Epoch 47/300\n",
      "2710/2710 - 10s - loss: 0.6189 - accuracy: 0.7158 - val_loss: 0.6010 - val_accuracy: 0.7269\n",
      "Epoch 48/300\n",
      "2710/2710 - 10s - loss: 0.6178 - accuracy: 0.7164 - val_loss: 0.6095 - val_accuracy: 0.7263\n",
      "Epoch 49/300\n",
      "2710/2710 - 10s - loss: 0.6177 - accuracy: 0.7161 - val_loss: 0.6039 - val_accuracy: 0.7283\n",
      "Epoch 50/300\n",
      "2710/2710 - 10s - loss: 0.6210 - accuracy: 0.7171 - val_loss: 0.6177 - val_accuracy: 0.7245\n",
      "Epoch 51/300\n",
      "2710/2710 - 10s - loss: 0.6170 - accuracy: 0.7169 - val_loss: 0.6115 - val_accuracy: 0.7252\n",
      "Epoch 52/300\n",
      "2710/2710 - 10s - loss: 0.6090 - accuracy: 0.7192 - val_loss: 0.6111 - val_accuracy: 0.7241\n",
      "Epoch 53/300\n",
      "2710/2710 - 10s - loss: 0.6188 - accuracy: 0.7171 - val_loss: 0.6247 - val_accuracy: 0.7271\n",
      "Epoch 54/300\n",
      "2710/2710 - 10s - loss: 0.6113 - accuracy: 0.7187 - val_loss: 0.6176 - val_accuracy: 0.7270\n",
      "Epoch 55/300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df.iloc[:,:266]\n",
    "Y = df.iloc[:,266:]\n",
    "input_dim = X.shape[1]\n",
    "encoder = LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(Y)\n",
    "# convert integers to dummy variables (one hot encoding)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, dummy_y, test_size=0.25, stratify=dummy_y)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "input = X.shape[1]\n",
    "# 隐藏层128\n",
    "model.add(Dense(128, input_shape=(input,)))\n",
    "model.add(Activation('relu'))\n",
    "# Dropout层用于防止过拟合\n",
    "model.add(Dropout(0.2))\n",
    "# 隐藏层128\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# 没有激活函数用于输出层，二分类问题，用sigmoid激活函数进行变换，多分类用softmax。\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "# 使用高效的 ADAM 优化算法以，二分类损失函数binary_crossentropy，多分类的损失函数categorical_crossentropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "# early stoppping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=50, verbose=2)\n",
    "# 训练\n",
    "history = model.fit(train_X, train_y, epochs=300, batch_size=30, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[early_stopping])# loss曲线\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# 预测\n",
    "y_pre = model.predict_classes(test_X)\n",
    "y_test=np.array([np.argmax(test_y[i]) for i in range(test_y.shape[0])])\n",
    "# \n",
    "print(classification_report(y_test, y_pre,labels=[0,1,2,3,4]))\n",
    "print(confusion_matrix(y_test, y_pre))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4649"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9043820750088044"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.99**10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
